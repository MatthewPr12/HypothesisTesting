---
title: "R Notebook"
authors: Yaroslav Korch, Anastasiia Senyk, Matvii Prytula
output:
  html_document:
    df_print: paged
---

# Hypothesis testing!
## Team members:
# Matvii Prytula, Anastasiia Senyk, Yaroslav Korch
...................................................................................................................................................................................................
...................................................................................................................................................................................................
...................................................................................................................................................................................................
...................................................................................................................................................................................................
...................................................................................................................................................................................................

```{r}

require(BSDA)
library(BSDA)
require(EnvStats)
library(EnvStats)

```


```{r}
id <- 21
k <- c(1:100)
l <- c(1:50)

# func to generate a_k for x_k
gen <- function(k) {
  return((k * log(k^2 * id + pi)) %% 1)
}
```


```{r}
#generating data
a_k <- sapply(k, gen)
a_l <- sapply(l + 100, gen)
x_k <- qnorm(a_k)
y_l <- qnorm(a_l)

x <- x_k
y <- y_l

#plotting data
my_plot <- function(data, title, breaks_num) {
  h <- hist(data, breaks = breaks_num, plot = FALSE)
  cuts <- cut(h$breaks, c(-Inf, -.005, Inf))
  plot(h, col = c("red", "black")[cuts], main = title)
}

my_plot(x_k, "x_k", 50)
my_plot(y_l, "y_l", 25)
```



# Problem 1. $H_0 : μ_1 =μ_2 \ vs. \ H_1 :μ_1 \ne μ_2; \ σ_1 = σ_2 =1$
```{r}
z.test(x = x, y = y, alternative = "t", sigma.x = 1, sigma.y = 1)
```

### We test whether **x_k** and **y_l** means are equal -- $H_0$, or not -- $H_1$. We can apply a z-test, since we are given the variance.
The **alternative = "t"** means two-sided check. The p-value turns out to be $\approx$ 0.49: $p_{val} > \alpha$ which tells that we should not reject the null hypothesis.
The difference of means lies in the $95%$ confidence interval, as expected.

# Problem 2. $H_0:σ_1=σ_2 vs. H_1:σ1_>σ_2; μ_1 \ and \ μ_2 \ are \ unknown$

```{r}
var.test(x, y, alternative = "g")
```
We do not reject the null hypothesis as we can see that the ratio of variances is $\approx 0.85$, which is close to $1$, and $p_{val} > \alpha$.
Also one can see that the ratio of variances lies in the confidence interval.


# 3. Using Kolmogorov–Smirnov test in R

### a) $\{x_k\}_{k=1}^{100}$ are normally distributed (with parameters calculated from the sample);
```{r}
ks.test(x, "pnorm")
```

$H_0$ -- data is drawn from a normal distribution. $H_1$ -- not from a normal one.
The $p-value$ is large, so we can't reject the null hypothesis.

### b) $\{|x_k|\}_{k=1}^{100}$ k=1 are exponentially distributed with λ = 1

```{r}
ks.test(abs(x), "exp")
```
$H_0$ -- data is drawn from a exponential distribution. $H_1$ -- not from an exponential one.
The $p-value$ is super tiny, so we can confidently reject the null hypothesis.

### c) $\{x_k\}_{k=1}^{100}$ and $\{y_l\}_{l=1}^{50}$ have the same distributions.
```{r}
ks.test(x, y)
```
$H_0$ -- x and y are drawn from the same distribution. $H_1$ -- from different distributions.
We do not have enough evidence to reject the null hypothesis, since $p-value$ is relatively big.



### Results: you never know :=)